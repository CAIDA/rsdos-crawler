version: "3.8"
services:
  doscrawler1:
    container_name: doscrawler1
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - doscrawler-data:/data/
    logging:
      driver: "json-file"
      options:
        max-size: "5mb"
        max-file: "10"
    depends_on:
      - kafka
      - zookeeper
    environment:
      - SIMPLE_SETTINGS=doscrawler.settings.production
      - BROKER=kafka://kafka:9092
      - BROKER_NAME=kafka
      - BROKER_PORT=9092
      - WORKER_ID=1
      - DUMP_DIR=/data/dumps/
      - SLACK_TOKEN=
      - SLACK_CHANNEL=
  doscrawler2:
    container_name: doscrawler2
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - doscrawler-data:/data/
    logging:
      driver: "json-file"
      options:
        max-size: "5mb"
        max-file: "10"
    depends_on:
      - kafka
      - zookeeper
    environment:
      - SIMPLE_SETTINGS=doscrawler.settings.production
      - BROKER=kafka://kafka:9092
      - BROKER_NAME=kafka
      - BROKER_PORT=9092
      - WORKER_ID=2
      - DUMP_DIR=/data/dumps/
      - SLACK_TOKEN=
      - SLACK_CHANNEL=
  doscrawler3:
    container_name: doscrawler3
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - doscrawler-data:/data/
    logging:
      driver: "json-file"
      options:
        max-size: "5mb"
        max-file: "10"
    depends_on:
      - kafka
      - zookeeper
    environment:
      - SIMPLE_SETTINGS=doscrawler.settings.production
      - BROKER=kafka://kafka:9092
      - BROKER_NAME=kafka
      - BROKER_PORT=9092
      - WORKER_ID=3
      - DUMP_DIR=/data/dumps/
      - SLACK_TOKEN=
      - SLACK_CHANNEL=
  doscrawler4:
    container_name: doscrawler4
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - doscrawler-data:/data/
    logging:
      driver: "json-file"
      options:
        max-size: "5mb"
        max-file: "10"
    depends_on:
      - kafka
      - zookeeper
    environment:
      - SIMPLE_SETTINGS=doscrawler.settings.production
      - BROKER=kafka://kafka:9092
      - BROKER_NAME=kafka
      - BROKER_PORT=9092
      - WORKER_ID=4
      - DUMP_DIR=/data/dumps/
      - SLACK_TOKEN=
      - SLACK_CHANNEL=
  doscrawler5:
    container_name: doscrawler5
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - doscrawler-data:/data/
    logging:
      driver: "json-file"
      options:
        max-size: "5mb"
        max-file: "10"
    depends_on:
      - kafka
      - zookeeper
    environment:
      - SIMPLE_SETTINGS=doscrawler.settings.production
      - BROKER=kafka://kafka:9092
      - BROKER_NAME=kafka
      - BROKER_PORT=9092
      - WORKER_ID=5
      - DUMP_DIR=/data/dumps/
      - SLACK_TOKEN=
      - SLACK_CHANNEL=
  kafka:
    image: wurstmeister/kafka
    hostname: kafka
    container_name: kafka
    ports:
    - "9092:9092"
    depends_on:
    - zookeeper
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_MESSAGE_MAX_BYTES=20971520
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_PROCESSING_GUARANTEE=exactly_once
      - KAFKA_NUM_PARTITIONS=5
      - KAFKA_BROKER_ID=1
  zookeeper:
    image: wurstmeister/zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
  mirrormaker:
    image: ambuds/mirror-maker
    container_name: mirrormaker
    depends_on:
      - kafka
      - zookeeper
      - doscrawler1
      - doscrawler2
      - doscrawler3
      - doscrawler4
      - doscrawler5
    environment:
      - DESTINATION=kafka:9092
      - SOURCE=kafka.rogues.caida.org:9392
      - WHITELIST=stardust.rsdos.attacks

volumes:
  doscrawler-data:
    driver: local
